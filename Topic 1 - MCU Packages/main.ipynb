{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ec5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydantic_settings langchain langchain-core langchain-google-genai langchain-qdrant fastembed langchain-community qdrant-client langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c572ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY: str\n",
    "    model_config = SettingsConfigDict(env_file=\".env\")\n",
    "\n",
    "env = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings_2 = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\", google_api_key=env.GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Distance\n",
    "\n",
    "collection_name = \"mcu_packages\"\n",
    "dimension = 3072\n",
    "distance = Distance.COSINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c7696",
   "metadata": {},
   "source": [
    "# Create Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mcu.json data\n",
    "import json\n",
    "\n",
    "with open(\"mcu.json\", \"r\") as f:\n",
    "    mcu_data = json.load(f)\n",
    "\n",
    "print(mcu_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can use FastEmbed for embeddings\n",
    "# from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "# embeddings = FastEmbedEmbeddings(cache_dir=\"./embedding_cache\", model_name=\"jinaai/jina-embeddings-v2-base-en\")\n",
    "# # https://qdrant.github.io/fastembed/examples/Supported_Models/#supported-text-embedding-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deeb5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import VectorParams\n",
    "\n",
    "if(client.collection_exists(collection_name=collection_name) == False):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=distance),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b681ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "import uuid\n",
    "i = 0\n",
    "for row in mcu_data:\n",
    "    i += 1\n",
    "    text = f\"Package Name: {row['name']}, Description: {row['description']}\"\n",
    "    emb = embeddings_2.embed_query(text)\n",
    "    print(i)\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=str(uuid.uuid4()),  # Generate a unique ID for each point\n",
    "                vector=emb, \n",
    "                payload={\n",
    "                    \"page_content\": text,\n",
    "                    \"metadata\": {\n",
    "                            \"id\": row['id'],\n",
    "                            \"name\": row['name'],\n",
    "                            \"description\": row['description'],\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4101842",
   "metadata": {},
   "source": [
    "# Create Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bb1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "def get_retriever():\n",
    "\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings_2,\n",
    "    )\n",
    "    \n",
    "    return vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, List\n",
    "\n",
    "@tool\n",
    "def search_mcu_packages(query: Annotated[str, \"search query must contain keywords related to MCU packages\"]) -> List[str]:\n",
    "    \"\"\"Search for MCU packages by name or description.\"\"\"\n",
    "    retriever = get_retriever()\n",
    "    results = retriever.invoke(query, k=10)\n",
    "    return [result.page_content for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f77e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_mcu_packages(\"gula darah, diabetes, paket medical check up, siloam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0dc87",
   "metadata": {},
   "source": [
    "# Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the Google Gemini API\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=env.GOOGLE_API_KEY,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that provides information about Siloam hospitals.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"Saya mau cek gula darah di siloam, ada paket apa aja ya ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33894fe",
   "metadata": {},
   "source": [
    "# Workflow for agent to use tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a130e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[str]\n",
    "    search: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb95d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(state: State):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are an expert in Medical Check-Up (MCU) packages.\n",
    "                You will provide keywords about the MCU packages based on the question.\n",
    "                The keywords should be relevant to the MCU packages available at Siloam hospitals.\n",
    "                Do not provide any other information.\n",
    "                If the question already contains keywords, you can return them as is.\n",
    "                Only return one keyword and in english.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"question\": state[\"question\"]})\n",
    "    return {\"search\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = search_mcu_packages(state[\"search\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f675a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: State):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "                You are an assistant that provides information about Medical Check-Up (MCU) packages at Siloam hospitals.\n",
    "                You will generate a response based on the context provided.\n",
    "                The response should be concise and relevant to the question asked.\n",
    "                package list knowledge: \n",
    "                {context}\n",
    "                If the context is empty, you can provide a general response about MCU packages.\n",
    "                Please always include related packages in your response.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    return {\"answer\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([get_context, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"get_context\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\n",
    "\t\"question\": \"Saya mau cek gula darah di siloam, ada paket apa aja ya ?\",\n",
    "\t\"context\": [],\n",
    "\t\"search\": \"\",\n",
    "\t\"answer\": \"\"\n",
    "})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
